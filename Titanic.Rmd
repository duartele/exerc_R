---
title: "Estudo sobre a base Titanic"
author: "Leandro Duarte"
date: "25/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, echo=FALSE, eval=TRUE}
# Use getwd() para ver se está no diretorio correto
df<-read.csv2("titanic.csv",colClasses = c("factor", "factor","factor","numeric","integer","integer","numeric", "factor","factor")) #Como importei a base - com os tipos corretos

# Usar attach(df) se não quiser ficar digitando df$ em cada variável

```
## Introdução e Resumo.

O objetivo primordial deste estudo é aplicar os conhecimentos aprendidos em Estatística Computacional com o professor Luís Machado (MECD), apresentando os passos e comandos utilizados no R. Além disso, foi ambicionado fazer uma Análise Descritiva (Uni e Muldimensional), Estimações (Pontual e Intervalar) e, por fim, apresentar alguns modelos para a previsão da variável resposta.

Para cumprir tais objetivos, foi escolhido trabalhar com a base de dados Titanic porque ela apresenta uma quantidade razoável de variáveis explicativas qualitativas (ordinais e nominais) e quantitativas (discretas e contínuas). Ademais, referida base é proveniente de um acidente histórico real que até hoje é relembrado pelas pessoas, as quais assistiram aos filmes e foram (ou desejaram ir) ao museu do Titanic, em Belfast.

Com efeito, o **RMS Titanic** foi um navio luxuoso construído para ser 'inafundável'. Partiu dia 10 de abril de 1912 com 2224 pessoas (passageiros e tripulantes) e o acidente ocorreu dia 15 de abril daquele ano, acarretando provavelmente em **mais de 1500 mortes** (foi estimado que o total de mortes está entre 1490 e 1635) [(ver Wikipédia)](https://en.wikipedia.org/wiki/Titanic).

Considerando que a base que temos acesso possui informações sobre **`r nrow(df)`** passageiros, ou seja, praticamente todos os existentes (2224 - 688 tripulantes aprox.= base), as medidas calculadas seriam populacionais e não amostrais, o que inviabilizaria fazer inferências ou construir modelos. Então, todo o exposto será uma abstração para focarmos nas técnicas computacionais e estatísticas.

Dito isto, consideraremos que estamos interessados em prever se um passageiro sobreviveu ao acidente, tendo posse algumas informações sobre ele, ou seja, a variável resposta será **survived**, caracterizada por 1 se o passageiro sobreviveu ao acidente ou 0 em caso contrário. A **proporção de sobreviventes** na amostra foi de **38,20%**.

Pela Análise da Descritiva, percebemos que a proporção de **mulheres** que sobreviveram ao acidente foi **maior** que a dos **homens** (**72,75%** contra **19,10%**). Também percebemos que as pessoas que viajaram na **primeira** classe tiveram uma proporção **maior** de sobrevivência (de **61,92%** contra **25,53%** dos que viajaram na **terceira** classe). Pessoas que embarcaram no porto **"C" (Cherbourg)** também possuíram uma proporção **maior** de sobrevivência (**55,56%** contra **33,56%** nos outros portos). Através da idade, percebemos que as **crianças e jovens** tiveram uma proporção **maior** de sobreviventes. Quanto à **fare**, vemos que os passageiros que pagaram mais **caro** nas passagens também tiveram uma proporção **maior** de sobreviventes. Pessoas que embarcaram **sozinhas** tiveram **menor** proporção de sobreviventes, sendo que recolhemos esta informação utilizando as variáveis **sibsp** e **parch**.

Percebemos também problemas em algumas dessas variáveis. Com efeito, **não temos 20,09%** dos valores da variável **age**. Como proceder diante desta situação? Além disso, muitos dos valores das variáveis **sibsp** e **parch** são zero, então será que eles realmente vão ajudar a explicar o comportamento da sobrevivência (ou não) de um passageiro? Há algumas incoerências entre os valores de **fare** e de **pclass**, pois há passageiros da terceira classe que pagaram mais caro que os que embarcaram na primeira classe. Será que há alguma explicação para isto? No decorrer do trabalho, apresentaremos algumas soluções para contornar esses problemas. 

No tocante à Inferência Estatística, obtemos a estimativa pontual de **38,20%** e construímos o intervalo **[0,3557 ; 0,4083]** com grau de confiança de 95% para a proporção de passageiros sobreviventes. Utilizando intervalos de confiança e Teste de Hipóteses (utilizando nível de significância de 5%), vimos quais diferenças encontradas na Análise Descritiva são significativas.

No capítulo referente à Modelagem, apresentamos modelos de Árvores de Decisão Simples, Regressão Logística e KNN, além de mostrarmos algumas técnicas de pré-processamento, construções de novas variáveis explicativas, combinações de modelos, critérios de seleção de modelos e também formas de tantar aumentar a acurácia na previsão da variável resposta através da "votação" de todos os modelos.

## Apresentação das Variáveis e Análise Descritiva Univariada.

    1. Dicionário de variáveis

+ **survived**: Sobrevivência (ou não) dos passageiros. Possíveis valores: 0 (morreu) ou 1 (sobreviveu);

+ **pclass**: Classe do Bilhete. Possíveis valores: 1(primeira), 2(segunda) ou 3 (terceira);
`
+ **sex**: Gênero do passageiro. Possíveis valores: female (feminino) ou male (masculino);

+ **age**: Idade (em anos). Possíveis valores: Para crianças menores de um ano, a idade pode assumir um valor contínuo (no intervalo  ]0,1[). Para mais velhos que isso, usa-se o valores discretos  {1,2,3...}. Quando tem o valor da forma xx.5 é porque a idade da pessoa foi estimada.

+ **sibsp**: Número de irmãos e/ou esposos a bordo. Possíveis valores: {0,1,2,3...};

+ **parch**: Número de pais e/ou filhos a bordo. Possíveis valores: {0,1,2,3...};

+ **fare**: Valor da tarifa paga. Possíveis valores: ]0,+∞[;

+ **embarked**: Porto de Embarque. Possíveis valores: C (Cherbourg), Q (Queenstown) ou S (Southampton);

+ **death**: Morte (ou não) do passageiro. Possíveis valores: 0 (não morreu) ou 1(morreu). Esta variável será descartada porque foi obtida pela variável **survived**.

Observe o tipo das variáveis e depois os primeiros registros em forma tabular:

```{r, echo=TRUE, eval=TRUE}
df<-subset(df, select=-death)
str(df)
head(df)
```

Também vale observar a tabela resumo, pois ela apresenta as frequências das variáveis qualitativas, medidas descritivas nas variáveis quantitativas e a quantidade de registros faltantes em cada atributo:

```{r}
summary(df)
```

Percebemos pela tabela resumo que cada categoria das variáveis qualitativas possuem ao menos 10% de representantes, o que garante alguma representatividade das categorias.

Quanto às informações faltantes, a única variável **alarmante** é a **age** (20,09% dos registros). Na seção 3.2, apresentaremos algumas formas de contornar este problema. Então, passemos para as Análises Descritivas. 

    2. Variáveis Qualitativas

    2.1 Variáveis Qualitativas Nominais
    
**Sex** (female ou male)

```{r, echo=TRUE}
label.pie<-c("Feminino","Masculino")
freq<-round(table(df$sex)/nrow(df)*100,2)
label.pie<-paste(label.pie,freq)
label.pie<-paste(label.pie,"%",sep="")
pie(x=table(df$sex), labels=label.pie, col = c("lightpink", "lightblue"))
```

Das `r  nrow(df)` observações, temos 466 mulheres (35,60%) e
843 homens (64,40%), ou seja, não temos valores faltantes e há predominância de homens na amostra. No gráfico a seguir, veremos se o gênero do passageiro ajudaria a explicar sua sobrevivência (ou não) ao acidente.

```{r, echo=TRUE}
barplot(table(df$survived,df$sex), xlab="Sobrevivência por Sexo", ylab="Frequência",
        legend.text = TRUE, beside=FALSE)
```

Pela apreciação desse gráfico, percebe-se que a **porporção** de sobrevivência das **mulheres** é **bem superior** a dos **homens** (**72,75%** contra **19,09%**), indicando assim que o gênero pode ajudar a explicar a sobrevivência de um passageiro.

**Embarked** (C - Cherbourg, Q - Queenstown ou S - Southampton)

```{r, echo=TRUE}
label.pie<-c("Na", "C","Q", "S")
freq<-round(table(df$embarked)/nrow(df)*100,2)
label.pie<-paste(label.pie,freq)
label.pie<-paste(label.pie,"%",sep="")
pie(x=table(df$embarked), labels=label.pie)
```

Percebemos que o Porto de **S** (Southampton) é o **mais frequente** e que esta variável possui apenas 2 valores faltantes. Quanto ao comportamento desta variável em relação a resposta, temos:

```{r, echo=TRUE}
barplot(table(df$survived,df$embarked), xlab="Sobrevivência por Porto de Embarque", ylab="Frequência",
        legend.text = TRUE, beside=TRUE)
```

Pela apreciação do gráfico, percebemos que a proporção de sobreviventes no porto C é **maior** que a proporção dos outros portos. Além disso, temos que a proporção de sobreviventes no porto Q está **próxima** da do S. Veremos no capítulo de Inferência Estatística se essas 3 categorias possuem diferenças significativas.

    2.2 Variáveis Qualitativas Ordinais

**Pclass** (1, 2 ou 3)

```{r, echo=TRUE}
label.pie<-c("Primeira","Segunda", "Terceira")
freq<-round(table(df$pclass)/nrow(df)*100,2)
label.pie<-paste(label.pie,freq)
label.pie<-paste(label.pie,"%",sep="")
pie(x=table(df$pclass), labels=label.pie)
```

Observando o gráfico acima, percebemos que a **Terceira** classe é a **mais frequente**. Quanto a proporção de sobreviventes, temos:

```{r, echo=TRUE}
barplot(table(df$survived,df$pclass), xlab="Sobrevivência por Classe de Embarque", ylab="Frequência",
        legend.text = TRUE, beside=TRUE)
```

Temos a sugestão de que quanto **pior** é a classe **menor** é a proporção de sobreviventes.

    3. Variáveis Quantitativas

    3.1 Variáveis Quantitativas Discretas

**Sibsp** (Número de irmãos e ou esposos)

```{r, echo=TRUE}
layout(matrix(c(1,2),ncol=2))
hist(df$sibsp, freq = TRUE ,ylab = "Frequência", xlab="Número de irmãos ou esposos",main="")
boxplot(df$sibsp)
```

Pelos gráficos acima, perebe-se que a **maioria** dos passageiros embarcou **sozinho** ou com apenas um(a) esposo(a)(ou irmã(o)). Com efeito, **apenas 4,35%** dos passageiros possuía 3 ou mais irmãos.
Levando isto em consideração, um gráfico de barras nos fornece melhor visualização. Nesse sentido, aprecie o seguinte gráfico:

```{r, echo=TRUE}
barplot(table(df$survived,df$sibsp), xlab="Sobrevivência por número de irmãos", ylab="Frequência",
        legend.text = TRUE, beside=TRUE)
```

Vemos pelo gráfico que os passageiros que embarcaram com 1 ou 2 irmãos tiveram **maior** proporção de sobreviventes que os que embarcaram sozinhos. Porém, os que possuíam 3 ou mais irmãos tiveram as **menores** proporções de sobreviventes. Podemos pensar em categorizar esta variável, caso agrupamentos possam nos ajudar a explicar se um passageiro sobreviveu ao acidente.

**Parch** (Número de pais ou filhos a bordo)

```{r, echo=TRUE}
layout(matrix(c(1,2),ncol=2))
hist(df$parch, freq = TRUE ,ylab = "Frequência", xlab="Número de pais ou filhos",main="")
boxplot(df$parch)
```

Assim como na **sibsp**, a maioria dos passageiros embarcou sozinho ou possuía apenas um ou dois filhos (ou pais). Utilizando o mesmo raciocínio da variável anterior, temos:

```{r, echo=TRUE}
barplot(table(df$survived,df$parch), xlab="Sobrevivência por número de pais ou filhos", ylab="Frequência",
        legend.text = TRUE, beside=TRUE)
```

Aqui parece que ter embarcado com filhos (ou pais) aumentou a proporção de sobreviventes. Porém, como há poucas observações com valores diferentes de 0, talvez teríamos que fazer uma dicotomia ("não possui" contra "possui").  

    3.2 Variáveis Quantitativas Contínuas

**Age**

```{r, echo=TRUE}
layout(matrix(c(1,2),ncol=2))
hist(df$age, freq = TRUE ,ylab = "Frequência", xlab="Idade",main="")
boxplot(df$age)
```

Pela apreciação dos gráficos, percebe-se que as faixas ]20,25] e ]25,30] são as mais frequentes, com uma leve assimetria à direita. Para ilustramos nossa assertiva, observe a distribuição da amostra com a comparação de uma curva normal.

```{r}
hist(df$age, freq = FALSE ,ylab = "Frequência", xlab="Idade",main="")
curve(dnorm(x,mean = mean(df$age, na.rm = TRUE),sd=sd(df$age, na.rm = TRUE)),add=TRUE)
rug(df$age)
abline(v=mean(df$age, na.rm = TRUE),col="red")
```

O gráfico abaixo serve para compararmos as distribuições dos passageiros que sobreviveram e a dos que faleceram ao acidente. Elas aparentam ser muito semelhantes.

```{r}
boxplot(df$age~df$survived, ylab = "Idade", xlab="Sobrevivência",main="")
```

Porém, observando os histogramas com a separação dos sobreviventes, percebe-se que crianças e adolescentes tiveram uma proporção maior de sobreviventes.

```{r}
mor<-df$age[df$survived==0]
viv<-df$age[df$survived==1]

layout(matrix(c(1,2),ncol=1))
hist(mor, freq = FALSE, breaks = 12, xlab = "Falecidos", main="")
hist(viv, freq = FALSE, col = "lightblue", breaks = 12, xlab = "Sobreviventes", main="")
```

Por fim, temos que esta variável apresenta 20.09% de seus valores faltantes, quantia esta expressiva. Além disso, analisando sua proporção de sobreviventes, vemos que é mais baixa que a dos outros adultos (**27,76%** contra **38,77%**).

Como algumas técnicas de modelagem não permitem a utilização de "missings", podemos contornar esse problema de algumas formas:

1. removendo registros faltantes - **quando são poucos** - aqui não é o caso, pois 20,09% da base está com valores faltantes;
2. substituindo o valor faltante pelo valor médio (ou a moda) amostral - não parece fazer sentido neste caso, pois a taxa de sobrevivência dos passageiros sem idade indicada é menor que a verificada na média;
3. excluíndo a variável do modelo - quando são muitos registros faltantes - 20,09% da base certamente não é um número pequeno, mas também não é exorbitante. Além disso, o fato da idade estar faltante parece ajudar a explicar o comportamento da variável resposta, então descartar esta variável não parece a melhor solução.

Diante do exposto, sugerimos agrupar a idade em três conglomerados: 1.Crianças e jovens; 2.Adultos; 3.Sem idade informada. Para essa nova variável (faixa_etaria) considere o seguinte código:

```{r}
calc_faixa_etaria<-function(idade=NA){
  if(is.na(idade)){
    faixa_etaria = "3.Sem idade informada"
    return(faixa_etaria)
  }else if(idade<=15){
    faixa_etaria = "1.Crianças e jovens"
    return(faixa_etaria)
  } else{
    faixa_etaria = "2.Adultos"
    return(faixa_etaria)
  }
}

df["faixa_etaria"]<-sapply(df$age,FUN=calc_faixa_etaria)
```

```{r, echo=TRUE}
label.pie<-c("Crianças","Adultos", "Sem idade")
freq<-round(table(df$faixa_etaria)/nrow(df)*100,2)
label.pie<-paste(label.pie,freq)
label.pie<-paste(label.pie,"%",sep="")

pie(x=table(df$faixa_etaria), labels=label.pie)
barplot(table(df$survived,df$faixa_etaria), xlab="Sobrevivência por Faixa Etária", ylab="Frequência",
        legend.text = TRUE, beside=FALSE)
```

Como dito, as crianças possuem uma maior proporção de sobreviventes, seguido dos adultos que sabemos a idade e os que não sabemos possuem uma proporção de sobreviventes.

**Fare**

```{r, echo=TRUE}
hist(df$fare, ylab = "Frequência", xlab = "Valor da Tarifa", main="")
```

Percebemos que a variável **fare** possui valores mais localizados à esquerda do gráfico. Uma das causas são os valores extremos que estão aumentando a amplitude de cada intervalo ("bins" é o termo em inglês). Antes de fazermos algum ajuste (aumentando o número de bins ou agrupando alguns valores), é de bom alvitre olharmos o comportamento desta variável em relação à resposta.

```{r}
boxplot(df$fare~df$survived, ylab = "Valor da Tarifa", xlab="Sobrevivência",main="")
```

Mesmo com os valores extremos distorcendo a escala, percebe-se que os que pagaram tarifas mais altas tiveram uma proporção maior de sobreviventes. Porém, será que este resultado  não está melhor descrito pela variável **pclass**? Para respondermos essas e outros questionamentos, faremos uma Análise Descritiva Multivariada.

## Análise Descritiva Multivariada.

Antes de começarmos, precisamos ressaltar que estamos no primeiro semestre, sem termos feito ainda Análise Multivariada (nem vimos técnicas de modelagem ainda). Então os procedimentos aplicados aqui foram guiados por intuições e podem não ser os utilizados por profissionais.

Nas seções anteriores, vimos que as pessoas que estavam na primeira classe e as que embarcaram no Porto C tiveram maiores proporções de sobreviventes. Será que há associação entre essas duas variáveis?

```{r, echo=TRUE}
layout(matrix(c(1,2),ncol=2))
barplot(table(df$embarked,df$pclass), xlab="Classe por Porto", ylab="Frequência",
        legend.text = TRUE, beside=FALSE)

barplot(table(df$pclass, df$embarked), xlab="Embarque por Classe", ylab="",
        legend.text = TRUE, beside=FALSE)

```

Pela apreciação desses gráficos, percebe-se que grande parte dos que embarcaram no porto Q estavam na terceira classe, mas os que embarcaram no S se espalharam pelas outras classes, lembrando que a taxa de sobrevicência do S e Q são próximas. Os que embarcaram no porto C, que tiveram uma proporção maior de sobreviventes, foram para as três classes, embora haja predominância na primeira. Portanto, mesmo havendo alguma  associação entre as variáveis, não parecem que essas variáveis são redundantes para a modelagem.  

Seguindo a lógica, supomos que os passageiros que pagaram as maiores tarifas foram para as primeiras classes, do contrário, haveria conflito de informações. Em todo o caso, precisamos averiguar se isto de fato ocorreu.

```{r}
boxplot(df$fare~df$pclass, ylab = "Valor da Tarifa", xlab="Classe",main="")
```

Verifica-se que, em geral, os que pagaram mais estão na primeira classe, mas há alguma confusão entre as classes nas tarifas mais baixas. Há observações, inclusive, que parece haver incoerências, por exemplo: por que 8 passageiros da terceira classe pagaram quase 60 valores, sendo que mais de 50 passageiros pagaram menos da metade e estavam na primeira classe?. Vale dizer, esses passageiros não possuíam esposas nem filhos a bordo.

Quanto a essa última informação vem o questionamento: será que há alguma associação entre a classe que embarcou e as variáveis **sibsp** ou **parch**? Vejamos os gráficos abaixo:

```{r, echo=TRUE}
layout(matrix(c(1,2),ncol=2))
barplot(table(df$sibsp,df$pclass), xlab="Classe por Número de Irmãos", ylab="Frequência",
        legend.text = FALSE, beside=FALSE) #legenda aqui atrapalha, pois temos muitas categorias - cores mais claras representam mais irmãos

barplot(table(df$pclass, df$sibsp), xlab="Número de Irmãos por Classe", ylab="",
        legend.text = TRUE, beside=FALSE)

layout(matrix(c(1,2),ncol=2))
barplot(table(df$parch,df$pclass), xlab="Classe por Número de Pais", ylab="Frequência",
        legend.text = FALSE, beside=FALSE) #legenda aqui atrapalha, pois temos muitas categorias - cores mais claras representam mais filhos

barplot(table(df$pclass, df$parch), xlab="Número de Pais por Classe", ylab="",
        legend.text = TRUE, beside=FALSE)
```

Para responder essa pergunta, podemos observar a correlação entre essas variáveis (apenas 0,3736). Também podemos colocar as variáveis num gráfico de dispersão:

```{r, echo=TRUE}
plot(df$sibsp~df$parch, xlab="Número de pais (ou filhos)", ylab="Número de irmãos (ou esposas)", main="")
abline(lm(df$sibsp~df$parch), col="red", lty=1, lwd=2)
```

Como essas variáveis tentam identificar se o passageiro embarcou sozinho, que tal unirmos essas duas informações numa nova variável? Para fazer isso, conseidere o seguinte código:

```{r}
sozinho<-function(a){
  if(a>0){
    sozinho = 0
    return(sozinho)
  }else{
    sozinho = 1
    return(sozinho)
  }
}
df["sozinho"]<-df$sibsp+df$parch
df["sozinho"]<-sapply(df$sozinho,FUN=sozinho)

barplot(table(df$survived,df$sozinho), xlab="Sozinho(SIM=1)", ylab="Frequência",
        legend.text = TRUE, beside=TRUE)
```

Pela observação do gráfico, percebemos que os passageiros que embarcaram sozinho tiveram uma **proporção menor** de sobreviventes. Então podemos considerar a utilização desta variável na modelagem (também podemos testar os outros agrupamentos propostos neste trabalho). Vale dizer, um dos propósitos da Análise Descritiva é a geração de "insights" e a construção de novas variáveis (ou agrupar existentes), técnica em inglês chamada de "Feature engineering".

Outro questionamento interessante é a saber a associação entre a idade e a **parch**. Não deveria ter, por exemplos, crianças que embarcaram sozinhas. Para verificarmos isso, vamos observar o gráfico com essas variáveis. 

```{r}
boxplot(df$parch~df$faixa_etaria, ylab = "Némero de pais (ou filhos)", xlab="Faixa etária",main="")
```

Como era de se esperar, as crianças possuem ao menos um pai (salvo poucas exceções). E como a maioria dos valores de **parch** é zero, os outros agrupamentos (adultos com ou sem idade informada) ficaram concentrados nos valores zero.

## Inferência Estatística.

Nesta seção, apresentaremos uma estimativa pontual e um intervalo de confiança para a variável **survived**. Além disso, durante a Análise Descritiva, percebemos que algumas variáveis pareciam ajudar a explicar o comportamento da variável resposta. Portanto, verificaremos se as diferenças acima encontradas são significativas (ou não) usando técnicas inferenciais.

    1. Estimação Pontual e Intervlar para a variável resposta **survived**

Seja Y uma variável aleatória que representa a sobrevivência de um passageiro, Y pode assumir 2 valores: 1 (sucesso) se o passageiro sobreviveu ao acidente e 0 (fracasso) em caso contrário. Neste caso, estaríamos interessados em descobir qual é a proporção de sucessos(p). Então Y ~ Bernoulli(p), sendo p o valor do parâmetro que queremos obter.

Assim, supondo que uma sucessão (Yn) seja independente e identicamente distribuída, teríamos que S = Y1 + Y2 + ... Yn teria uma distribuição Binomial (S ~ Bin(n,p)). Além disso, considerando que a n é grande, podemos usar o TLC (Teorema do Limite Central) e aproximar a distribuição S por uma Normal com média np e variância np(1-p).

Deste modo, como nossa amostra y = (y1, y2, ...., y1309) é uma realização particular de Y = (Y1, Y2, ...., Y1309), o p que queremos encontrar pode ser estimado da seguinte forma:
p_est = S/n ~ N(p,p(1-p)/n), em que S = quantidade de sobreviventes na amostra e n é o tamanho da amostra.

```{r}
p_est<- table(df$survived)[2]/nrow(df)
sd <- sqrt(p_est*(1-p_est)/nrow(df))
LI <- p_est - qnorm(0.975)*sd
LS <- p_est + qnorm(0.975)*sd

#Forma utilizando funções do R: binom.test
binom.test(table(df$survived)[2],nrow(df))
#Diferença bem pequena. Aqui é usada a distribuição Binomial, enquanto que o intervalo acima foi obtido pela normal 
```

Logo, p_est = 500/1309 = 0,381971 (Estimativa Pontual). Adotando o grau de confiança de 95%, temos o intervalo de confiança IC = [LI;LS] = [0.3557 ; 0.4083].  

De acordo com o site da Wikipédia, a embarcação possuiu 2224 pessoas (passageiros e tripulantes) e o número total de mortes estimado está entre 1490 e 1635, ou seja, a porporção de sobreviventes estaria entre [0.2648 ; 0.3300]. Percebe-se, assim, que a interseção dos intervalos é vazia.

Diante do exposto, podemos formular e testar as seguintes hipóteses: H0:a proporção de sobreviventes é de 0.33 (máximo do intervalo da Wikipédia) vs H1: a proporção de sobreviventes é superior a 0.33? Este teste é unilateral à direita (H0: p = 0.33 vs H1: p > 0.33). Vale dizer, poderíamos fazer um teste bilateral (H0: p = 0.33 vs H1: p != 0.33), mas neste caso poderia ser respodido pelo próprio intervalo de confiança que construímos e, assim, rejeitaríamos H0 ao nível de significância de 5%.

```{r}
prop.test(x=500,n=1309,p=0.33,alternative = "greater",conf.level = 0.95)

```

Portanto, considerando um nível de significância de 5%, rejetimanos H0, ou seja, há evidências significativas que a proporção de sobreviventes não é de 33%.

Cabe ressaltar, porém, que os valores apresentados no site não se referem apenas aos passageiros, mas também aos tripulantes. Então, pode ser que a proporção de sobreviventes dos tripulantes foi menor, o que diminuiu a proporção de sobreviventes total. Outra possibilidade é que os poucos passageiros que não fizem parte da amostra também fizeram com que a porporção de sobreviventes real diminuísse.

    2. Verificação das diferenças na taxa de sobrevivência nas variáveis explicativas.

    2.1 **Sexo - sex**

Vimos que as mulheres pareciam ter uma proporção de sobrevivência superior à dos homens. Para verificar nossa assertiva, podemos fazer um teste de hipóteses, em que H0: p_mulheres = p_homens vs H1: p_mulheres != p_homens. Outra forma de verificar isso seria construir um intervalo de confiança para a diferença das proporções e se esse intervalo contiver o valor zero, significa que não podemos rejeitar H0, ou seja, não teríamos evidência de que a diferença das estimativas é significativa. Utilizaremos neste (e em todos os outros) um nível de significância de 5% (teste de hipóteses) e 95% de confiança (intervalos de confiança).

```{r}
p_xx<-table(df$survived,df$sex)[2,1]/table(df$sex)[1]
p_xy<-table(df$survived,df$sex)[2,2]/table(df$sex)[2]  

se <- sqrt(p_xx*(1-p_xx)/table(df$sex)[1] + p_xy*(1-p_xy)/table(df$sex)[2]) 
p_xx-p_xy+c(-1,1)*qnorm(0.975)*se

#Outra forma (utilizando uma função do R):
#prop.test
prop.test(x=c(table(df$survived,df$sex)[2,1],table(df$survived,df$sex)[2,2]),n=c(table(df$sex)[1],table(df$sex)[2]))

#Podemos testar, também, se p_xx é maior que p_xy 
prop.test(x=c(table(df$survived,df$sex)[2,1],table(df$survived,df$sex)[2,2]),n=c(table(df$sex)[1],table(df$sex)[2]), alternative = "greater")

```

Obtemos, portanto o intervalo de confiança (0.4881 ; 0.5848). Como não contem o valor zero, rejeitamos a hipótese nula (proporções de sobrevivência iguais). Além, disso, fica evidente que a proporção de sobrevivência das mulheres **é maior** que a dos homens.

    2.2 **Classe que Embarcou - pclass**
    
Também percebemos que as pessoas que viajaram na primeira classe tiveram uma proporção **maior** de sobrevivência (de **61,92%** contra **25,53%** dos que viajaram na terceira classe). Podemos fazer o teste: H0: p1=p2=p3 vs H1: há alguma diferença entre as proporções. Porém, é mais interessante fazer dois testes: primeiro verificar se p1=p2 e depois verificar se p2=p3.

```{r}
#H1: p_1 é maior que p_2? 
prop.test(x=c(table(df$survived,df$pclass)[2,1],table(df$survived,df$pclass)[2,2]),n=c(table(df$pclass)[1],table(df$pclass)[2]), alternative = "greater")
```

Portanto, ao nível de significância de 5%, rejeita-se H0, ou seja, rejeitamos que as proporções de sobreviventes nas classes 1 e 2 sejam iguais.

```{r}
#H1: p_2 é maior que p_3? 
prop.test(x=c(table(df$survived,df$pclass)[2,2],table(df$survived,df$pclass)[2,3]),n=c(table(df$pclass)[2],table(df$pclass)[3]), alternative = "greater")
```

Portanto, ao nível de significância de 5%, rejeita-se H0, ou seja, rejeitamos que as proporções de sobreviventes nas classes 2 e 3 sejam iguais.

    2.2 **Porto em que Embarcou - embarked**

Pessoas que embarcaram no porto "C" (Cherbourg) também possuíram uma proporção **maior** de sobrevivência (**55,56%** contra **33,56%** nos outros portos). Vale dizer, o tamanho expressivo da amostra facilita a rejeição de H0 (observe os valores-p dos outros testes, quase todos foram praticamente zero). Aqui, porém, pode ser que não rejeitemos que as proporções dos outros portos sejam iguais.

```{r}
#H1: p_Q é igual a p_S? - Teste bilateral
prop.test(x=c(table(df$survived,df$embarked)[2,3],table(df$survived,df$embarked)[2,4]),n=c(table(df$embarked)[3],table(df$embarked)[4]), alternative = "two.sided")
```

Portanto, Não rejeitamos H0 ao nível de significância de 5%, ou seja, não descartamos a hipótese de que as proporções dos Portos Q e S são iguais. Como desencargo de consciência, vamos testar se a proporção de sobreviventes no porto C é maior que a de Q.

```{r}
#H1: p_C é superior a p_Q? - Teste unilateral
prop.test(x=c(table(df$survived,df$embarked)[2,2],table(df$survived,df$embarked)[2,3]),n=c(table(df$embarked)[2],table(df$embarked)[3]), alternative = "greater")

```

    2.3 **Idade - age**

Através da idade, percebemos que as **crianças e jovens** tiveram uma proporção **maior** de sobreviventes. Além disso, dividimos os passageiros em três grupos: **"1.Crianças e jovens**; **2.Adultos** e **3.Sem idade informada**. Para essa nova variável (faixa_etaria) considere os seguintes testes:

```{r}
#H1: p_Crianças é superior a p_Adultos? - Teste unilateral
prop.test(x=c(table(df$survived,df$faixa_etaria)[2,1],table(df$survived,df$faixa_etaria)[2,2]),n=c(table(df$faixa_etaria)[1],table(df$faixa_etaria)[2]), alternative = "greater")

```

Portanto, rejeitamos H0 ao nível de significância de 5%, ou seja, a proporção de sobreviventes das crianças é dierente (e maior) do que a dos adultos com idade informada. Para testar se proporções de sobreviventes com idade informada e sem são iguais, verifique o seguinte teste, com o qual concluímos que podemos rejeitar H0:

```{r}
#H1: p_Adultos_idade é superior a p_Adultos_sem_idade? - Teste unilateral
prop.test(x=c(table(df$survived,df$faixa_etaria)[2,2],table(df$survived,df$faixa_etaria)[2,3]),n=c(table(df$faixa_etaria)[2],table(df$faixa_etaria)[3]), alternative = "greater")

```

Os outros testes podem ser feitos de forma semelhante com que apresentamos aqui. Então, para não ficar repetitivo, deixemos a cargo do leitor. Contudo, vale dizer, quando fizermos os modelos de previsão para a variável resposta, os algoritmos apresentarão os resultados dos testes efetuados.
    
## Modelagem.

Como vimos, a variável resposta é dicotômica e os modelos mais adequados para sua previsão são os de classificação. Mais precisamente, os modelos supervisionados, pois temos acesso ao resultado da variável nos elementos da amostra.

Iremos apresentar 3 modelos: **Regressão Logística**, **Árvore de Decisão (Simples)** e o **KNN**. O melhor modelo será o que apresentar a maior acurácia, que mede o número total de acertos dividido pelo número total de previsões.  Vale dizer, ainda, que há maneiras de refinar os modelos, como a escolha dos melhores hiperparâmetros, a construção de novas variáveis (feature engineering), junções de modelos, etc...

Para medir a acurácia, precisamos dividir a amostra em dois grupos: uma para "treinar" os modelos (train) e outra para validar os resultados porque, do contrário, o modelo pode "decorar" as respostas, o que é chamado de **overfitting**. Geralmente, é utilizado 70% da amostra para treinar os modelos e os outros 30% são destinado a validação.

    1.Pré-processamento

Antes de construirmos os modelos, precisamos fazer alguns pré-processamentos, como criar labels para as variáveis categóricas, tratar os valores faltantes e dividir a amostra em treino e teste (já mencionado). Quando aplicar o KNN, precisamos fazer alguns outros pré-processamentos, mas para não ficar confusas as bases, faremos as devidas alterações na seção do KNN.

```{r}
#Categorizando as variáveis faixa_etária e sozinho
df$faixa_etaria<-factor(df$faixa_etaria)
df$sozinho<-factor(df$sozinho)

#Tratando os valores faltantes
#Para idade, vou usar a variável faixa_etaria, mas em todo o caso vou deixar a idade sem valores valtantes
df$age[is.na(df$age)]<-mean(df$age,na.rm = TRUE)
df$fare[is.na(df$fare)]<-mean(df$fare,na.rm = TRUE) #só tinha uma obs faltante
df$embarked[df$embarked==""]<-"S" #Só tem 2 obs faltantes - coloquei na mais frequente
df$embarked<-factor(df$embarked) #Quando importei, ficou com 4 fatores: C,Q,S e "", por isso eu refactorizei
```

Para fazer a divisão em treino e teste, poderíamos usar um pacote (por exemplo, "caTools"). Porém, em vez de instalarmos um pacote, podemos simplesmente gerar números aleatórios, conforme se verifica abaixo:

```{r}
set.seed(17) #Para manter a mesma sequência pseudo-aleatória
sample<-sort(sample(nrow(df),nrow(df)*0.7))
train<-df[sample,]
val<-df[-sample,]
```

Pronto, o pré-processamento já foi efetuado.

    2.Regressão Logística

Para construírmos um modelo de regressão logística, podemos utilizar a função glm.

```{r}
train<-subset(train, select=-age)
m1<-glm(formula = survived ~ ., data = train, family="binomial")
summary(m1)
```

Com o resultado do primeiro modelo, percebemos que as variáveis fare, embarkedQ e parch foram rejeitadas. Primeiro retiraremos fare e executar o modelo de novo para ver se embarked e sozinho1 continuarão a ser rejeitadas ( outras podem ser rejeitadas agora).

```{r}
train<-subset(train, select=-fare)
m2<-glm(formula = survived ~ ., data = train, family="binomial")
summary(m2)
```

Novamente, vemos que as variáveis embarkedQ e parch foram rejeitadas. Considerando que parch já está sendo explicada pelas variáveis sibsp e sozinho, podemos excluí-la do modelo. Quanto à embarkedQ, vimos na parte inferencial que não rejeitamos a hipótese de que a proporção de sobreviventes dos que embarcaram no porto Q não era diferente da dos que embarcaram no porto S. Então, usaremos essa igualdade na obtenção do modelo final.

```{r}
df["embarked_agg"]<-df$embarked
df$embarked_agg[df$embarked_agg=="Q"]<-"S"
df$embarked_agg<-factor(df$embarked_agg)
train<-df[sample,]
val<-df[-sample,]
train<-subset(train, select=-c(age,fare,parch,embarked))
mf<-glm(formula = survived ~ ., data = train, family="binomial")
summary(mf)
```

Como nenhuma variável foi rejeitada (todos os betas são significamente diferentes de zero), veremos agora se os coeficientes estão coerentes com o que seria esperado. Podemos ver, por exemplo, que a medida que piora a classe de embarque, diminui a probabilidade de sobrevivência (coeficientes estão negativos e "punem" cada vez mais). Contudo, há um pequeno conflito na variável **sibsp**, pois com 1 ou 2 irmãos, a proporção de sobreviventes é maior que a de 0, mas o sinal do coeficiente é negativo. Isto acontece porque com 3 ou mais irmãos vai diminuindo a proporção de sobreviventes e quanto ao 0, ele já é punido pela variável **sozinho**. Até dá para refinar essas variáveis utilizando o agrupamento sugerido na análise descritiva, mas não teríamos melhoria prática.

Então, apliquemos este modelo na base de validação para obter a matriz de confusão e, consequentemente, a acurácia do modelo.

```{r}
res<-predict(mf,val,type="response")
confmatrix<-table(verd=val$survived,pred=res>0.5)
acc<-(confmatrix[1,1]+confmatrix[2,2])/sum(confmatrix)
print(acc)
```

Percebe-se que dos 236 (199+37) passageiros que não sobreviveram, acertamos 199 e dos 157 (108+49) que sobreviveram, acertamos 108. Logo, acertamos 307 dos 393 passageiros existentes na base de validação, o que dá uma **acurácia** de **78,12%**.

Outra forma de avaliar a qualidade do nosso modelo é verificar se a acurácia dos sobreviventes é próxima da dos não sobreviventes. Olhando a matriz de confusão, a acurácia dos sobreviventes foi de **84,32%** (199/236) e a de não sobreviventes foi de **68,79%** (108/157), ou seja, nosso modelo não prevê tão bem os que faleceram.

    3.Árvore de Decisão Simples

O modelo de Árvore de Decisão é de fácil interpretação e lida muito bem com diversos tipos de variáveis (a variável resposta, por exemplo, pode ser qualitativa ou quantitativa), também lida bem com valores faltantes e não requer pré-processamentos (embora manteremos os feitos na primeira seção).

Além disso, ele pode ser usado como ponto de partida para outros modelos. Vale dizer, ainda, que podemos aplicar a técnica de Random Forest e melhorar ainda mais a performance do modelo, pese o fato de ficar um pouco menos interpretativo.

O ponto negativo da Árvore de Decisão é não conseguirmos controlar bem o número de folhas produzidas. Até podemos especificar quantos entroncamentos queremos, mas as vezes com tamanho "n" o modelo fica "underfit" e com "n+1" já fica "overfit". Para exemplificar nossa assertiva, é possível construir uma árvore que dê acurácia de 100% para a base de treinamento, mas obviamente nesses casos o modelo costuma ir muito mal na base de validação (e, consequentemente, nas futuras previsões que tenhamos que fazer na prática).

Para construir um modelo de Árvore de Decisão, precisamos importar as bibliotecas rpart e rpart.plot. Após isto, dividiremos a base em treino e validação e já construiremos uma árvore.

```{r}
library(rpart)
library(rpart.plot)
```

```{r}
train<-df[sample,]
val<-df[-sample,]
tree<-rpart(survived ~., data=train)
prp(tree)
```

Basta olharmos a figura acima que rapidamente entendemos quais variáveis foram utilizadas na construção do modelo e sua importância. A primeira foi **sex**, sendo auxiliada pelas variáveis **age** e **pclass**, a qual foi auxiliada pela variável **fare**. Ao percorrermos um caminho da árvore, percebemos qual foi a previsão do modelo para um passageiro com as características do caminho. Por exemplo, homens com menos de 6,5 anos e que possuíam menos de 3 irmãos foram classificados como sobreviventes.

Aplicando este modelo na base de validação, obtemos os seguintes resultaddos:

```{r}
pred<-predict(tree, val, type="class")
acc<-sum(table(pred,val$survived)[1,1],table(pred,val$survived)[2,2])/length(pred)
print(acc)
```

Temos, portanto, uma acurácia de **78,12%** (coincidentemente, a mesma que a obtida no de regressão logística!). Quanto à matriz de confusão, observe a seguinte matriz:

```{r}
table(pred,real=val$survived)
```

Dos 236 passageiros que não sobreviveram, houve uma acurácia de **89,83%** (212/236) e dos que 157 que sobreviveram tivemos uma acurácia de **60,51%** (95/157). Nesse quesito, portanto, o modelo de regressão logística foi mais equilibrado.

    4.KNN 

A ideia do KNN é classificar um novo elemento observando os k elementos mais próximos, sendo k um valor que chamamos de hiperparâmetro do modelo. Não existe uma fórmula para se obter k, geralmente usa números ímpares para evitar empates (por exemplo, se k fosse 4 e perto do elementos que queremos prever temos 2 passageiros que sobreviveram e 2 que não sobreviveram, qual seria a predição para esse elemento?). Obteremos esse valor treinando o algoritmo iterativamente e verificando qual apresentou a maior acurácia. 

Outro problema que o knn enfrenta é que a variável resposta precisa ser equilibrada, do contrário, fica difícil para a categoria com pouca representatividade "vencer na votação". No caso em tela, temos que a proporção de sobreviventes é de 38,20%, temos, então, um leve desbalanceamento.

Precisamos que todas as variáveis explicativas sejam numéricas. Então, precisaremos fazer alguns outros pré-processamentos (além dos realizados na seção 1).

```{r}
library(caret)
```

```{r}
target<-subset(df, select=survived)
df<-subset(df, select=-c(survived,embarked_agg))
df$pclass<-as.integer(df$pclass)#Não quero criar dummies nesta variável porque a ordem importa: classe1>classe2>classe3
dummy<-dummyVars(" ~. ", data=df)
df<-data.frame(predict(dummy,newdata=df))
```

Também precisamos que as variáveis estejam normalizadas (todas as variáveis terão escalas de zero a um, ou seja, não é padronização!) para que todas as distâncias tenham o mesmo peso. Certamente tem alguma função para fazer isso, mas simplesmente podemos construir uma linha:

```{r}
normalize<-function(x) return((x-min(x))/(max(x)-min(x)))
#Aplicando a normalização na base:
df_norm<-as.data.frame(lapply(df, normalize))
X_train<-df_norm[sample,] #seed(17) já foi fixado
X_val<-df_norm[-sample,]
y_train<-target[sample,]
y_val<-target[-sample,]
```

Podemos, agora, aplicar o algoritmo KNN. Para exemplificar, comecemos por k=3.

```{r}
require(class)
```


```{r}
m1<-knn(train = X_train, test = X_val, cl=y_train, k=3)
acc<-sum(table(m1,y_val)[1,1],table(m1,y_val)[2,2])/length(y_val)
print(acc)
```

Percebe-se, portanto com nossa primeira tentativa, vale dizer, com um valor "chutado" de k, conseguimos uma acurácia melhor que o da regressão logística. Como não conseguimos entender quais variáveis estão ajudando (ou atrapalhando) na decisão, resta-nos melhorar o algoritmo procurando por melhores valores de k.

```{r}
l_acc<-c()#inicializando o vetor de acc
for( i in 1:41){
  m1<-knn(train = X_train, test = X_val, cl=y_train, k=i)
  acc<-sum(table(m1,y_val)[1,1],table(m1,y_val)[2,2])/length(y_val)
  l_acc<-append(l_acc,acc)
}

cat('Para k = ',which.max(l_acc)," temos acc = ",max(l_acc))
```

Portanto, o melhor valor de k para a base de validação é **k=13** com uma acurácia de **80,15%**. O gráfico a seguir mostra o acc de todos os k gerados:

```{r}
plot(l_acc,xaxt="n")
axis(1,at=1:40)
abline(v=13,col="green")
```

Por fim, vamos olhar a matriz de confusão, para entender quais foram os erros e acertos do método.

```{r}
m_final<-knn(train = X_train, test = X_val, cl=y_train, k=13) #Salvei um modelo em cima do outro pra economizar memória, por isso precisa retreinar com k=max
table(m_final,y_val)#Obs: pode mudar um pouco o resultado, por haver retreinamento!!!!
```

De forma análoga ao que fizemos na regressão logística, podemos verificar que a acurácia dos sobreviventes foi de **91,95%** (217/236) e a de não sobreviventes foi de **64,67%** (97/150), o que se afigura bem discrepante, ou seja, nosso modelo não acerta bem quem sobreviveu ao acidente, indo nesse quesito pior que o obtido na regressão logística.


    5.Escolha do melhor modelo

Podemos escolher qual modelo vamos aplicar na vida real com base em diversos critérios como, por exemplo, performance, interpretabilidade, velocidade de previsão. Vale dizer que este último quesito é também muito importante. Por exemplo, tem empresas que possuem mais de 7 milhões de clientes com base superior a 100 variáveis, aplicar o KNN seria completamente inviável, pois a cada nova previsão, o algoritmo precisa fazer todas as contas de todas as distâncias.

Poderíamos, também, combinar todos os modelos e prevermos a variável resposta como o resultado das "votações". Por exemplo, suponha que para um determinado passageiro teríamos que o modelo de KNN e o de Regressão Logística classificaram o passageiro como sobrevivente e o de Árvore de Decisão o classificou como não-sobrevivente. Nessa caso, teríamos que a classificação de sobrevivência igual a 1 (passageiro sobreviveu) "ganhou" a votação.

Além disso, caso escolhêssemos um modelo como o melhor, ainda teríamos a oportunidade de tentar melhorar ainda mais sua performance, fazendo transformações de algumas variáveis, criando outras variáveis, usando outros tipos de métodos do modelo. Por exemplo, o KNN usou a distância euclidiana, poderíamos testar com a distância de manhattan, usar técnicas de componentes principais, "boosting", "bagging" e assim obtermos diversos modelos. Porém, por outro lado, sempre estamos correndo o risco de cometer **overfitting** e, assim, após tanto trabalho, o modelo não funcionar na vida real.

Quanto aos modelos apresentados neste trabalho, os três tiveram acurácias parecidas. Se optássemos por escolhero com maior acurácia, escolheríamos o KNN com k=13, se a interpretabilidade fosse o critério principal, a Árvore de Decisão simples seria o modelo mais adequado e caso quiséssemos o modelo mais equilibrado para prever tanto os sobreviventes com o não sobreviventes, nesse caso escolheríamos o de Regressão Logística.

## Conclusões.

Por meio da base do Titanic, conseguimos aprender ainda mais sobre o acidente histórico que ocorreu há pouco mais de 100 anos. De fato, vimos que o **gênero feminino, as crianças e os mais abastados financeiramente**, os quais compraram bilhetes para a primeira classe, foram os que tiveram **maior proporção de sobrevivência**, sendo que tais variáveis tiveram influências estatísticamente significativas.

Também extrapolamos os resultados obtidos na amostra para a população, obtendo o Intervalo de Confiança [0,3557 ; 0,4083] e a estimativa pontual de **0,3819** para a proporção de sobreviventes na população constituída pelos passageiros que embarcaram no Titanic.

Por fim, apresentamos um modelo de Regressão Logística que apresentou uma acurácia de **78,12%** para uma base de validação, um de Árvore de Decisão que também apresentou uma acurácia de **78,12%** para referida base e um modelo de KNN com k=13, que apresentou uma acurácia de **80,15%**, sendo esses valores excelentes, considerando que a base não apresenta uma muitas variáveis explicativas.

## Agradecimentos.

Este trabalho conseguiu utilizar os conhecimentos adquiridos no primeiro semestre do mestrado de Estatística para Ciências de Dados da Universidade do Minho, mais precisamente, com menos de 2 meses de curso.

Com efeito, para a Análise Descritiva Univariada, muito do conhecimento foi obtido na matéria de Fundamentos e Aplicações de Estatística. Na seção de Inferência Estatística, todos os testes e códigos do R lá utilizados foram aprendidos na cadeira de mesmo nome. A análise dos "betas" de cada variável foi aprendida na matéria de Modelos Lineares (por analogia aos Beta0 e Beta1 da Regressão Logística). Na parte de modelagem, utilizei o conhecimento adquirido na palestra do One Day Meeting patrocinado pela UMinho, que contou ainda com técnicas de Naive Bayes (poderia ter sido construído um modelo deste no presente trabalho). Por fim, o mais importante para a confecção deste trabalho foi aprendido na cadeira de Computação, pois foi aprendido a utilizar o R e o SPSS (este não precisou ser utilizado aqui, mas também é uma ferramenta fundamental para todos que utilizam a Estatística em seus trabalhos e estudos).

Diante do exposto, foi imprescindível a criação de um capítulo exclusivo para o agradecimento à UMinho.

## Referências.

Fatos históricos sobre o Titanic: (https://en.wikipedia.org/wiki/Titanic)

Cursos de Python, Data Science e Machine Learning: (https://www.youtube.com/c/DataICMC) - são alunos da Universidade de São Paulo que criaram este canal para compartilhar conhecimento.

Site com diversos cursos gratuitos, bases de dados e competições de Machine Learning: (https://www.kaggle.com)

Outros Canais do Youtube onde aprendi comandos sobre modelagem utilizando o R:
(https://www.youtube.com/c/rdjalayer)
(https://www.youtube.com/c/SimplilearnOfficial)
