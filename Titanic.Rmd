---
title: "Estudo sobre a base Titanic"
author: "Leandro Duarte"
date: "25/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, echo=FALSE, eval=TRUE}
# Use getwd() para ver se está no diretorio correto
df<-read.csv2("titanic.csv",colClasses = c("factor", "factor","factor","numeric","integer","integer","numeric", "factor","factor")) #Como importei a base - com os tipos corretos

# Usar attach(df) se não quiser ficar digitando df$ em cada variável

```
## Introdução e Resumo.

O objetivo primordial deste estudo é aplicar os conhecimentos aprendidos em Estatística Computacional com o professor Luís Machado (MECD), apresentando os passos e comandos utilizados no R. Além disso, foi ambicionado fazer uma Análise Descritiva (Uni e Muldimensional), Estimações (Pontual e Intervalar) e, por fim, apresentar alguns modelos para a previsão da variável resposta.

Para cumprir tais objetivos, foi escolhido trabalhar com a base de dados Titanic porque ela apresenta uma quantidade razoável de variáveis explicativas qualitativas (ordinais e nominais) e quantitativas (discretas e contínuas). Ademais, referida base é proveniente de um acidente histórico real que até hoje é relembrado pelas pessoas, as quais assistiram aos filmes e foram (ou desejaram ir) ao museu do Titanic, em Belfast.

Com efeito, o **RMS Titanic** foi um navio luxuoso construído para ser 'inafundável'. Partiu dia 10 de abril de 1912 com 2224 pessoas (passageiros e tripulantes) e o acidente ocorreu dia 15 de abril daquele ano, acarretando provavelmente em **mais de 1500 mortes** (foi estimado que o total de mortes está entre 1490 e 1635) [(ver Wikipédia)](https://en.wikipedia.org/wiki/Titanic).

Considerando que a base que temos acesso possui informações sobre `r nrow(df)` passageiros, ou seja, praticamente todos os existentes (2224 - 688 tripulantes ~= base), as medidas calculadas seriam populacionais e não amostrais, o que inviabilizaria fazer inferências ou construir modelos. Então, todo o exposto será uma abstração para focarmos nas técnicas computacionais e estatísticas.

Dito isto, consideraremos que estamos interessados em prever se um passageiro sobreviveu ao acidente, tendo posse de algumas informações sobre ele, ou seja, a variável resposta será **"survived"**, caracterizada por 1 se o passageiro sobreviveu ao acidente ou 0 em caso contrário. A **proporção de sobreviventes** na amostra foi de **`r round(table(df$survived)[2]/nrow(df)*100,2)`%**.

Pela Análise da Descritiva, percebemos que a proporção de mulheres que sobreviveram ao acidente foi **maior** que a dos homens (**72,75%** contra **19,10%**). Também percebemos que as pessoas que viajaram na primeira classe tiveram uma proporção **maior** de sobrevivência (de **61,92%** contra **25,53%** dos que viajaram na terceira classe). Pessoas que embarcaram no porto "C" (Cherbourg) também possuíram uma proporção **maior** de sobrevivência (**55,56%** contra **33,56%** nos outros portos). Através da idade, percebemos que as **crianças e jovens** tiveram uma proporção **maior** de sobrevivência. Quanto à **fare**, vemos que os passageiros que pagaram mais caro nas passagens também tiveram uma proporção maior de sobrevivência.

Em contrapartida, as variáveis sibsp e parch **não parecem** contribuir para entendermos melhor a variável resposta porque a maioria de seus valores é 0. Além disso, a variável idade apresenta muitos valores faltantes. Precisamos verificar, ainda, se as variáveis associadas. Apresentaremos algumas possíveis formas de contornar os problemas das variáveis mencionadas neste parágrafo.  

No tocante à Inferência Estatística, construímos o intervalo [0.3557 ; 0.4083] com grau de confiança de 95% para a proporção de passageiros sobreviventes. Vimos ainda quais diferenças encontradas na Análise Descritiva são significativas.

Por fim, foi apresentado um modelo de regressão logística, o qual utilizou as variáveis xpto e que apresentou uma acurácia de 75%, um modelo de KNN, o qual mostrou uma acurácia de 70% quando escolhido o hiperparâmetro de 5 vizinhos e também uma árvore de decisão, que apresentou uma acurácia de 90%, sendo "vitorioso" o modelo ypto. Cabe ressaltar, podemos melhorar os modelos fazendo outros ajustes nas variáveis e, também, substituindo a Árvore de Decisão (Decision Tree) por uma Random Forest, pois esta é geralmente melhor. 

## Apresentação das Variáveis e Análise Descritiva Univariada.

    1. Dicionário de variáveis

+ **survived**: Sobrevivência (ou não) dos passageiros. Possíveis valores: 0 (morreu) ou 1 (sobreviveu);

+ **pclass**: Classe do Bilhete. Possíveis valores: 1(primeira), 2(segunda) ou 3 (terceira);
`
+ **sex**: Gênero do passageiro. Possíveis valores: female (feminino) ou male (masculino);

+ **age**: Idade (em anos). Possíveis valores: Para crianças menores de um ano, a idade pode assumir um valor contínuo (no intervalo  ]0,1[). Para mais velhos que isso, usa-se o valores discretos  {1,2,3...}. Quando tem o valor da forma xx.5 é porque a idade da pessoa foi estimada.

+ **sibsp**: Número de irmãos e/ou esposos a bordo. Possíveis valores: {0,1,2,3...};

+ **parch**: Número de pais e/ou filhos a bordo. Possíveis valores: {0,1,2,3...};

+ **fare**: Valor da tarifa paga. Possíveis valores: ]0,+∞[;

+ **embarked**: Porto de Embarque. Possíveis valores: C (Cherbourg), Q (Queenstown) ou S (Southampton);

+ **death**: Morte (ou não) do passageiro. Possíveis valores: 0 (não morreu) ou 1(morreu). Esta variável será descartada porque foi obtida pela variável **survived**.

Observe o tipo das variáveis e depois os primeiros registros em forma tabular:

```{r, echo=TRUE, eval=TRUE}
df<-subset(df, select=-death)
str(df)
head(df)
```

Também vale observar a tabela resumo, pois ela apresenta as frequências das variáveis qualitativas, medidas descritivas nas variáveis quantitativas e a quantidade de registros faltantes em cada atributo:

```{r}
summary(df)
```

Percebemos pela tabela resumo que cada categoria das variáveis qualitativas possuem ao menos 10% de representantes, o que garante alguma representatividade das categorias.

Quanto às informações faltantes, a única variável alarmante é a idade (20,09% dos registros). Na seção 3.2, apresentaremos algumas formas de contornar este problema. Então, passemos para as Análises Descritivas. 

    2. Variáveis Qualitativas

    2.1 Variáveis Qualitativas Nominais
    
**Sex** (female ou male)

```{r, echo=TRUE}
label.pie<-c("Feminino","Masculino")
freq<-round(table(df$sex)/nrow(df)*100,2)
label.pie<-paste(label.pie,freq)
label.pie<-paste(label.pie,"%",sep="")
pie(x=table(df$sex), labels=label.pie, col = c("lightpink", "lightblue"))
```

Das `r  nrow(df)` observações, temos `r table(df$sex)[1]` mulheres (`r round(table(df$sex)[1]/nrow(df)*100,2)`%) e
`r table(df$sex)[2]` homens (`r round(table(df$sex)[2]/nrow(df)*100,2)`%), sem
valores faltantes, portanto.
No gráfico a seguir, veremos para cada uma dessas categorias o comportamento da variável resposta.

```{r, echo=TRUE}
barplot(table(df$survived,df$sex), xlab="Sobrevivência por Sexo", ylab="Frequência",
        legend.text = TRUE, beside=FALSE)
```

Pela apreciação desse gráfico, percebe-se que a porporção de sobrevivência das mulheres é **bem superior** a dos homens (72,75% contra 19,09%), indicando assim que a variável sexo pode ajudar a explicar a sobrevivência de um passageiro.

**Embarked** (C - Cherbourg, Q - Queenstown ou S - Southampton)

```{r, echo=TRUE}
label.pie<-c("Na", "C","Q", "S")
freq<-round(table(df$embarked)/nrow(df)*100,2)
label.pie<-paste(label.pie,freq)
label.pie<-paste(label.pie,"%",sep="")
pie(x=table(df$embarked), labels=label.pie)
```

Percebemos que o Porto de Southampton é o mais frequente e que esta variável só possui 2 valores faltantes. Quanto ao comportamento desta variável em relação a resposta, temos:

```{r, echo=TRUE}
barplot(table(df$survived,df$embarked), xlab="Sobrevivência por Porto de Embarque", ylab="Frequência",
        legend.text = TRUE, beside=TRUE)
```

Pela apreciação do gráfico, percebemos que apenas no porto C a proporção de sobreviventes foi **maior** que a de falecidos. Além disso, temos que a proporção de sobreviventes no porto Q está **próxima** da do S.

    2.2 Variáveis Qualitativas Ordinais

**Pclass** (1, 2 ou 3)

```{r, echo=TRUE}
label.pie<-c("Primeira","Segunda", "Terceira")
freq<-round(table(df$pclass)/nrow(df)*100,2)
label.pie<-paste(label.pie,freq)
label.pie<-paste(label.pie,"%",sep="")
pie(x=table(df$pclass), labels=label.pie)
```

Observando o gráfico acima, percebemos que a Terceira classe é a mais frequente. Quanto a proporção de sobreviventes, temos:

```{r, echo=TRUE}
barplot(table(df$survived,df$pclass), xlab="Sobrevivência por Classe de Embarque", ylab="Frequência",
        legend.text = TRUE, beside=TRUE)
```

Temos a sugestão de que quanto pior é a classe menor é a proporção de sobreviventes, sendo que houve mais sobreviventes na primeira classe que falecidos.

    3. Variáveis Quantitativas

    3.1 Variáveis Quantitativas Discretas

**Sibsp** (Número de irmãos e ou esposos)

```{r, echo=TRUE}
layout(matrix(c(1,2),ncol=2))
hist(df$sibsp, freq = TRUE ,ylab = "Frequência", xlab="Número de irmãos ou esposos",main="")
boxplot(df$sibsp)
```

Pelos gráficos acima, perebe-se que a maioria dos passageiros embarcou sozinho ou com apenas um(a) esposo(a)(ou irmã(o)). Com efeito, apenas 4,35% dos passageiros possuía 3 ou mais irmãos.
Levando isto em consideração, talvez seja mais interessante pensar nesta variável como se fosse categórica ordinal, o que resultaria em:

```{r, echo=TRUE}
barplot(table(df$survived,df$sibsp), xlab="Sobrevivência por número de irmãos", ylab="Frequência",
        legend.text = TRUE, beside=TRUE)
```

Quando olhamos as proporções de sobreviventes, não conseguimos ver uma associação linear. De fato, os que embarcaram sozinhos tiveram menor taxa de sobrevivência dos que embarcaram com 1 ou 2 irmãos, porém com 3 ou mais irmãos a taxa de sobrevivência já fica bem baixa. Fazer um agrupamento em 3 conglomerados ("não possui", "possui 1 ou 2" e "possui mais de 2") pode até dar uma contribuição na modelagem, mas o resultado não seria interpretativo. Então, talvez seja melhor não utilizarmos esta variável.

**Parch** (Número de pais ou filhos a bordo)

```{r, echo=TRUE}
layout(matrix(c(1,2),ncol=2))
hist(df$parch, freq = TRUE ,ylab = "Frequência", xlab="Número de pais ou filhos",main="")
boxplot(df$parch)
```

Assim como na **sibsp**, a maioria dos passageiros embarcou sozinho ou possuía apenas um ou dois filhos (ou pais). Utilizando o mesmo raciocínio da variável anterior, temos:

```{r, echo=TRUE}
barplot(table(df$survived,df$parch), xlab="Sobrevivência por número de pais ou filhos", ylab="Frequência",
        legend.text = TRUE, beside=TRUE)
```

Aqui parece que ter embarcado com filhos (ou pais) aumentou a proporção de sobreviventes. Porém, como há poucas observações com valores diferentes de 0, talvez teríamos que fazer uma dicotomia ("não possui" contra "possui").  

    3.2 Variáveis Quantitativas Contínuas

**Age**

```{r, echo=TRUE}
layout(matrix(c(1,2),ncol=2))
hist(df$age, freq = TRUE ,ylab = "Frequência", xlab="Idade",main="")
boxplot(df$age)
```

Pela apreciação dos gráficos, percebe-se que as faixas ]20,25] e ]25,30] são as mais frequentes, com uma leve assimetria à direita. Para ilustramos nossa assertiva, observe a distribuição da amostra com a comparação de uma curva normal.

```{r}
hist(df$age, freq = FALSE ,ylab = "Frequência", xlab="Idade",main="")
curve(dnorm(x,mean = mean(df$age, na.rm = TRUE),sd=sd(df$age, na.rm = TRUE)),add=TRUE)
rug(df$age)
abline(v=mean(df$age, na.rm = TRUE),col="red")
```

O gráfico abaixo serve para compararmos as distribuições dos passageiros que sobreviveram e a dos que faleceram ao acidente. Elas aparentam ser muito semelhantes.

```{r}
boxplot(df$age~df$survived, ylab = "Idade", xlab="Sobrevivência",main="")
```

Porém, observando os histogramas com a separação dos sobreviventes, percebe-se que crianças e adolescentes tiveram uma proporção maior de sobreviventes.

```{r}
mor<-df$age[df$survived==0]
viv<-df$age[df$survived==1]

layout(matrix(c(1,2),ncol=1))
hist(mor, freq = FALSE, breaks = 12, xlab = "Falecidos", main="")
hist(viv, freq = FALSE, col = "lightblue", breaks = 12, xlab = "Sobreviventes", main="")
```

Por fim, temos que esta variável apresenta 20.09% de seus valores faltantes, quantia esta expressiva. Além disso, analisando sua proporção de sobreviventes, vemos que é mais baixa que a dos outros adultos (**27,76%** contra **38,77%**).

Como algumas técnicas de modelagem não permitem a utilização de "missings", podemos contornar esse problema de algumas formas:

1. removendo registros faltantes - **quando são poucos** - aqui não é o caso, pois 20,09% da base está com valores faltantes;
2. substituindo o valor faltante pelo valor médio (ou a moda) amostral - não parece fazer sentido neste caso, pois a taxa de sobrevivência dos passageiros sem idade indicada é menor que a verificada na média;
3. excluíndo a variável do modelo - quando são muitos registros faltantes - 20,09% da base certamente não é um número pequeno, mas também não é exorbitante. Além disso, o fato da idade estar faltante parece ajudar a explicar o comportamento da variável resposta, então descartar esta variável não parece a melhor solução.

Diante do exposto, sugerimos agrupar a idade em três conglomerados: 1.Crianças e jovens; 2.Adultos; 3.Sem idade informada. Para essa nova variável (faixa_etaria) considere o seguinte código:

```{r}
calc_faixa_etaria<-function(idade=NA){
  if(is.na(idade)){
    faixa_etaria = "3.Sem idade informada"
    return(faixa_etaria)
  }else if(idade<=15){
    faixa_etaria = "1.Crianças e jovens"
    return(faixa_etaria)
  } else{
    faixa_etaria = "2.Adultos"
    return(faixa_etaria)
  }
}

df["faixa_etaria"]<-sapply(df$age,FUN=calc_faixa_etaria)
```

```{r, echo=TRUE}
label.pie<-c("Crianças","Adultos", "Sem idade")
freq<-round(table(df$faixa_etaria)/nrow(df)*100,2)
label.pie<-paste(label.pie,freq)
label.pie<-paste(label.pie,"%",sep="")

pie(x=table(df$faixa_etaria), labels=label.pie)
barplot(table(df$survived,df$faixa_etaria), xlab="Sobrevivência por Faixa Etária", ylab="Frequência",
        legend.text = TRUE, beside=FALSE)
```

Como dito, as crianças possuem uma maior proporção de sobreviventes, seguido dos adultos que sabemos a idade e os que não sabemos possuem uma proporção de sobreviventes.

**Fare**

```{r, echo=TRUE}
hist(df$fare, ylab = "Frequência", xlab = "Valor da Tarifa", main="")
```

Percebemos que a variável **fare** possui valores mais localizados à esquerda do gráfico. Uma das causas são os valores extremos que estão aumentando a amplitude de cada intervalo ("bins" é o termo em inglês). Antes de fazermos algum ajuste (aumentando o número de bins ou agrupando alguns valores), é de bom alvitre olharmos o comportamento desta variável em relação à resposta.

```{r}
boxplot(df$fare~df$survived, ylab = "Valor da Tarifa", xlab="Sobrevivência",main="")
```

Mesmo com os valores extremos distorcendo a escala, percebe-se que os que pagaram tarifas mais altas tiveram uma proporção maior de sobreviventes. Porém, será que este resultado  não está melhor descrito pela variável **pclass**? Para respondermos essas e outros questionamentos, faremos uma Análise Descritiva Multivariada.

## Análise Descritiva Multivariada.

Antes de começarmos, precisamos ressaltar que estamos no primeiro semestre, sem termos feito ainda Análise Multivariada (nem vimos técnicas de modelagem ainda). Então os procedimentos aplicados aqui foram guiados por intuições e podem não ser os utilizados por profissionais.

Nas seções anteriores, vimos que as pessoas que estavam na primeira classe e as que embarcaram no Porto C tiveram maiores proporções de sobreviventes. Será que há associação entre essas duas variáveis?

```{r, echo=TRUE}
layout(matrix(c(1,2),ncol=2))
barplot(table(df$embarked,df$pclass), xlab="Classe por Porto", ylab="Frequência",
        legend.text = TRUE, beside=FALSE)

barplot(table(df$pclass, df$embarked), xlab="Embarque por Classe", ylab="",
        legend.text = TRUE, beside=FALSE)

```

Pela apreciação desses gráficos, percebe-se que grande parte dos que embarcaram no porto Q estavam na terceira classe, mas os que embarcaram no S se espalharam pelas outras classes, lembrando que a taxa de sobrevicência do S e Q são próximas. Os que embarcaram no porto C, que tiveram uma proporção maior de sobreviventes, foram para as três classes, embora haja predominância na primeira. Portanto, mesmo havendo alguma  associação entre as variáveis, não parecem que essas variáveis são redundantes para a modelagem.  

Seguindo a lógica, supomos que os passageiros que pagaram as maiores tarifas foram para as primeiras classes, do contrário, haveria conflito de informações. Em todo o caso, precisamos averiguar se isto de fato ocorreu.

```{r}
boxplot(df$fare~df$pclass, ylab = "Valor da Tarifa", xlab="Classe",main="")
```

Verifica-se que, em geral, os que pagaram mais estão na primeira classe, mas há alguma confusão entre as classes nas tarifas mais baixas. Há observações, inclusive, que parece haver incoerências, por exemplo: por que 8 passageiros da terceira classe pagaram quase 60 valores, sendo que mais de 50 passageiros pagaram menos da metade e estavam na primeira classe?. Vale dizer, esses passageiros não possuíam esposas nem filhos a bordo.

Quanto a essa última informação vem o questionamento: será que há alguma associação entre a classe que embarcou e as variáveis **sibsp** ou **parch**? Vejamos os gráficos abaixo:

```{r, echo=TRUE}
layout(matrix(c(1,2),ncol=2))
barplot(table(df$sibsp,df$pclass), xlab="Classe por Número de Irmãos", ylab="Frequência",
        legend.text = FALSE, beside=FALSE) #legenda aqui atrapalha, pois temos muitas categorias - cores mais claras representam mais irmãos

barplot(table(df$pclass, df$sibsp), xlab="Número de Irmãos por Classe", ylab="",
        legend.text = TRUE, beside=FALSE)

layout(matrix(c(1,2),ncol=2))
barplot(table(df$parch,df$pclass), xlab="Classe por Número de Pais", ylab="Frequência",
        legend.text = FALSE, beside=FALSE) #legenda aqui atrapalha, pois temos muitas categorias - cores mais claras representam mais filhos

barplot(table(df$pclass, df$parch), xlab="Número de Pais por Classe", ylab="",
        legend.text = TRUE, beside=FALSE)
```

Para responder essa pergunta, podemos observar a correlação entre essas variáveis (apenas 0,3736). Também podemos colocar as variáveis num gráfico de dispersão:

```{r, echo=TRUE}
plot(df$sibsp~df$parch, xlab="Número de pais (ou filhos)", ylab="Número de irmãos (ou esposas)", main="")
abline(lm(df$sibsp~df$parch), col="red", lty=1, lwd=2)
```

Como essas variáveis tentam identificar se o passageiro embarcou sozinho, que tal unirmos essas duas informações numa nova variável? Para fazer isso, conseidere o seguinte código:

```{r}
sozinho<-function(a){
  if(a>0){
    sozinho = 0
    return(sozinho)
  }else{
    sozinho = 1
    return(sozinho)
  }
}
df["sozinho"]<-df$sibsp+df$parch
df["sozinho"]<-sapply(df$sozinho,FUN=sozinho)

barplot(table(df$survived,df$sozinho), xlab="Sozinho(SIM=1)", ylab="Frequência",
        legend.text = TRUE, beside=TRUE)
```

Pela observação do gráfico, percebemos que os passageiros que embarcaram sozinho tiveram uma **proporção menor** de sobreviventes. Então podemos considerar a utilização desta variável na modelagem (também podemos testar os outros agrupamentos propostos neste trabalho). Vale dizer, um dos propósitos da Análise Descritiva é a geração de "insights" e a construção de novas variáveis (ou agrupar existentes), técnica em inglês chamada de "Feature engineering".

Outro questionamento interessante é a saber a associação entre a idade e a **parch**. Não deveria ter, por exemplos, crianças que embarcaram sozinhas. Para verificarmos isso, vamos observar o gráfico com essas variáveis. 

```{r}
boxplot(df$parch~df$faixa_etaria, ylab = "Némero de pais (ou filhos)", xlab="Faixa etária",main="")
```

Como era de se esperar, as crianças possuem ao menos um pai (salvo poucas exceções). E como a maioria dos valores de **parch** é zero, os outros agrupamentos (adultos com ou sem idade informada) ficaram concentrados nos valores zero.

## Inferência Estatística.

Nesta seção, apresentaremos uma estimativa pontual e um intervalo de confiança para a variável **survived**. Além disso, durante a Análise Descritiva, percebemos que algumas variáveis pareciam ajudar a explicar o comportamento da variável resposta. Portanto, verificaremos se as diferenças acima encontradas são significativas (ou não) usando técnicas inferenciais.

    1. Estimação Pontual e Intervlar para a variável resposta **survived**

Seja Y uma variável aleatória que representa a sobrevivência de um passageiro, Y pode assumir 2 valores: 1 (sucesso) se o passageiro sobreviveu ao acidente e 0 (fracasso) em caso contrário. Neste caso, estaríamos interessados em descobir qual é a proporção de sucessos(p). Então Y ~ Bernoulli(p), sendo p o valor do parâmetro que queremos obter.

Assim, supondo que uma sucessão (Yn) seja independente e identicamente distribuída, teríamos que S = Y1 + Y2 + ... Yn teria uma distribuição Binomial (S ~ Bin(n,p)). Além disso, considerando que a n é grande, podemos usar o TLC (Teorema do Limite Central) e aproximar a distribuição S por uma Normal com média np e variância np(1-p).

Deste modo, como nossa amostra y = (y1, y2, ...., y1309) é uma realização particular de Y = (Y1, Y2, ...., Y1309), o p que queremos encontrar pode ser estimado da seguinte forma:
p_est = S/n ~ N(p,p(1-p)/n), em que S = quantidade de sobreviventes na amostra e n é o tamanho da amostra.

```{r}
p_est<- table(df$survived)[2]/nrow(df)
sd <- sqrt(p_est*(1-p_est)/nrow(df))
LI <- p_est - qnorm(0.975)*sd
LS <- p_est + qnorm(0.975)*sd

#Forma utilizando funções do R: binom.test
binom.test(table(df$survived)[2],nrow(df))
#Diferença bem pequena. Aqui é usada a distribuição Binomial, enquanto que o intervalo acima foi obtido pela normal 
```

Logo, p_est = 500/1309 = 0,381971 (Estimativa Pontual). Adotando o grau de confiança de 95%, temos o intervalo de confiança IC = [LI;LS] = [0.3557 ; 0.4083].  

De acordo com o site da Wikipédia, a embarcação possuiu 2224 pessoas (passageiros e tripulantes) e o número total de mortes estimado está entre 1490 e 1635, ou seja, a porporção de sobreviventes estaria entre [0.2648 ; 0.3300]. Percebe-se, assim, que a interseção dos intervalos é vazia.

Diante do exposto, podemos formular e testar as seguintes hipóteses: H0:a proporção de sobreviventes é de 0.33 (máximo do intervalo da Wikipédia) vs H1: a proporção de sobreviventes é superior a 0.33? Este teste é unilateral à direita (H0: p = 0.33 vs H1: p > 0.33). Vale dizer, poderíamos fazer um teste bilateral (H0: p = 0.33 vs H1: p != 0.33), mas neste caso poderia ser respodido pelo próprio intervalo de confiança que construímos e, assim, rejeitaríamos H0 ao nível de significância de 5%.

```{r}
prop.test(x=500,n=1309,p=0.33,alternative = "greater",conf.level = 0.95)

```

Portanto, considerando um nível de significância de 5%, rejetimanos H0, ou seja, há evidências significativas que a proporção de sobreviventes não é de 33%.

Cabe ressaltar, porém, que os valores apresentados no site não se referem apenas aos passageiros, mas também aos tripulantes. Então, pode ser que a proporção de sobreviventes dos tripulantes foi menor, o que diminuiu a proporção de sobreviventes total. Outra possibilidade é que os poucos passageiros que não fizem parte da amostra também fizeram com que a porporção de sobreviventes real diminuísse.

    2. Verificação das diferenças na taxa de sobrevivência nas variáveis explicativas.

    2.1 **Sexo - sex**

Vimos que as mulheres pareciam ter uma proporção de sobrevivência superior à dos homens. Para verificar nossa assertiva, podemos fazer um teste de hipóteses, em que H0: p_mulheres = p_homens vs H1: p_mulheres != p_homens. Outra forma de verificar isso seria construir um intervalo de confiança para a diferença das proporções e se esse intervalo contiver o valor zero, significa que não podemos rejeitar H0, ou seja, não teríamos evidência de que a diferença das estimativas é significativa. Utilizaremos neste (e em todos os outros) um nível de significância de 5% (teste de hipóteses) e 95% de confiança (intervalos de confiança).

```{r}
p_xx<-table(df$survived,df$sex)[2,1]/table(df$sex)[1]
p_xy<-table(df$survived,df$sex)[2,2]/table(df$sex)[2]  

se <- sqrt(p_xx*(1-p_xx)/table(df$sex)[1] + p_xy*(1-p_xy)/table(df$sex)[2]) 
p_xx-p_xy+c(-1,1)*qnorm(0.975)*se

#Outra forma (utilizando uma função do R):
#prop.test
prop.test(x=c(table(df$survived,df$sex)[2,1],table(df$survived,df$sex)[2,2]),n=c(table(df$sex)[1],table(df$sex)[2]))

#Podemos testar, também, se p_xx é maior que p_xy 
prop.test(x=c(table(df$survived,df$sex)[2,1],table(df$survived,df$sex)[2,2]),n=c(table(df$sex)[1],table(df$sex)[2]), alternative = "greater")

```

Obtemos, portanto o intervalo de confiança (0.4881 ; 0.5848). Como não contem o valor zero, rejeitamos a hipótese nula (proporções de sobrevivência iguais). Além, disso, fica evidente que a proporção de sobrevivência das mulheres **é maior** que a dos homens.

    2.2 **Classe que Embarcou - pclass**
    
Também percebemos que as pessoas que viajaram na primeira classe tiveram uma proporção **maior** de sobrevivência (de **61,92%** contra **25,53%** dos que viajaram na terceira classe). Podemos fazer o teste: H0: p1=p2=p3 vs H1: há alguma diferença entre as proporções. Porém, é mais interessante fazer dois testes: primeiro verificar se p1=p2 e depois verificar se p2=p3.

```{r}
#H1: p_1 é maior que p_2? 
prop.test(x=c(table(df$survived,df$pclass)[2,1],table(df$survived,df$pclass)[2,2]),n=c(table(df$pclass)[1],table(df$pclass)[2]), alternative = "greater")
```

Portanto, ao nível de significância de 5%, rejeita-se H0, ou seja, rejeitamos que as proporções de sobreviventes nas classes 1 e 2 sejam iguais.

```{r}
#H1: p_2 é maior que p_3? 
prop.test(x=c(table(df$survived,df$pclass)[2,2],table(df$survived,df$pclass)[2,3]),n=c(table(df$pclass)[2],table(df$pclass)[3]), alternative = "greater")
```

Portanto, ao nível de significância de 5%, rejeita-se H0, ou seja, rejeitamos que as proporções de sobreviventes nas classes 2 e 3 sejam iguais.

    2.2 **Porto em que Embarcou - embarked**

Pessoas que embarcaram no porto "C" (Cherbourg) também possuíram uma proporção **maior** de sobrevivência (**55,56%** contra **33,56%** nos outros portos). Vale dizer, o tamanho expressivo da amostra facilita a rejeição de H0 (observe os valores-p dos outros testes, quase todos foram praticamente zero). Aqui, porém, pode ser que não rejeitemos que as proporções dos outros portos sejam iguais.

```{r}
#H1: p_Q é igual a p_S? - Teste bilateral
prop.test(x=c(table(df$survived,df$embarked)[2,3],table(df$survived,df$embarked)[2,4]),n=c(table(df$embarked)[3],table(df$embarked)[4]), alternative = "two.sided")
```

Portanto, Não rejeitamos H0 ao nível de significância de 5%, ou seja, não descartamos a hipótese de que as proporções dos Portos Q e S são iguais. Como desencargo de consciência, vamos testar se a proporção de sobreviventes no porto C é maior que a de Q.

```{r}
#H1: p_C é superior a p_Q? - Teste unilateral
prop.test(x=c(table(df$survived,df$embarked)[2,2],table(df$survived,df$embarked)[2,3]),n=c(table(df$embarked)[2],table(df$embarked)[3]), alternative = "greater")

```

    2.3 **Idade - age**

Através da idade, percebemos que as **crianças e jovens** tiveram uma proporção **maior** de sobreviventes. Além disso, dividimos os passageiros em três grupos: **"1.Crianças e jovens**; **2.Adultos** e **3.Sem idade informada**. Para essa nova variável (faixa_etaria) considere os seguintes testes:

```{r}
#H1: p_Crianças é superior a p_Adultos? - Teste unilateral
prop.test(x=c(table(df$survived,df$faixa_etaria)[2,1],table(df$survived,df$faixa_etaria)[2,2]),n=c(table(df$faixa_etaria)[1],table(df$faixa_etaria)[2]), alternative = "greater")

```

Portanto, rejeitamos H0 ao nível de significância de 5%, ou seja, a proporção de sobreviventes das crianças é dierente (e maior) do que a dos adultos com idade informada. Para testar se proporções de sobreviventes com idade informada e sem são iguais, verifique o seguinte teste, com o qual concluímos que podemos rejeitar H0:

```{r}
#H1: p_Adultos_idade é superior a p_Adultos_sem_idade? - Teste unilateral
prop.test(x=c(table(df$survived,df$faixa_etaria)[2,2],table(df$survived,df$faixa_etaria)[2,3]),n=c(table(df$faixa_etaria)[2],table(df$faixa_etaria)[3]), alternative = "greater")

```

Os outros testes podem ser feitos de forma semelhante com que apresentamos aqui. Então, para não ficar repetitivo, deixemos a cargo do leitor. Contudo, vale dizer, quando fizermos os modelos de previsão para a variável resposta, os algoritmos apresentarão os resultados dos testes efetuados.
    
## Modelagem.

Como vimos, a variável resposta é dicotômica e os modelos mais adequados para sua previsão são os de classificação. Mais precisamente, os modelos supervisionados, pois temos acesso ao resultado da variável nos elementos da amostra.

Iremos apresentar 3 modelos: **Regressão Logística**, **Árvore de Decisão (Simples)** e o **KNN**. O melhor modelo será o que apresentar a maior acurácia, que mede o número total de acertos dividido pelo número total de previsões.  Vale dizer, ainda, que há maneiras de refinar os modelos, como a escolha dos melhores hiperparâmetros, a construção de novas variáveis (feature engineering), junções de modelos, etc...

Para medir a acurácia, precisamos dividir a amostra em dois grupos: uma para "treinar" os modelos (train) e outra para validar os resultados porque, do contrário, o modelo pode "decorar" as respostas, o que é chamado de **overfitting**. Geralmente, é utilizado 70% da amostra para treinar os modelos e os outros 30% são destinado a validação.

    1.Pré-processamento

Antes de construirmos os modelos, precisamos fazer alguns pré-processamentos, como criar labels para as variáveis categóricas, tratar os valores faltantes e dividir a amostra em treino e teste (já mencionado). Quando aplicar o KNN, precisamos fazer alguns outros pré-processamentos, mas para não ficar confusas as bases, faremos as devidas alterações na seção do KNN.

```{r}
#Categorizando as variáveis faixa_etária e sozinho
df$faixa_etaria<-factor(df$faixa_etaria)
df$sozinho<-factor(df$sozinho)

#Tratando os valores faltantes
#Para idade, vou usar a variável faixa_etaria, mas em todo o caso vou deixar a idade sem valores valtantes
df$age[is.na(df$age)]<-mean(df$age,na.rm = TRUE)
df$fare[is.na(df$fare)]<-mean(df$fare,na.rm = TRUE) #só tinha uma obs faltante
df$embarked[df$embarked==""]<-"S" #Só tem 2 obs faltantes - coloquei na mais frequente
df$embarked<-factor(df$embarked) #Quando importei, ficou com 4 fatores: C,Q,S e "", por isso eu refactorizei
```

Para fazer a divisão em treino e teste, poderíamos usar um pacote (por exemplo, "caTools"). Porém, em vez de instalarmos um pacote, podemos simplesmente gerar números aleatórios, conforme se verifica abaixo:

```{r}
set.seed(17) #Para manter a mesma sequência pseudo-aleatória
sample<-sort(sample(nrow(df),nrow(df)*0.7))
train<-df[sample,]
val<-df[-sample,]
```

Pronto, o pré-processamento já foi efetuado.

    2.Regressão Logística

Para construírmos um modelo de regressão logística, podemos utilizar a função glm.

```{r}
train<-subset(train, select=-age)
m1<-glm(formula = survived ~ ., data = train, family="binomial")
summary(m1)
```

Com o resultado do primeiro modelo, percebemos que as variáveis fare, embarkedQ e parch foram rejeitadas. Primeiro retiraremos fare e executar o modelo de novo para ver se embarked e sozinho1 continuarão a ser rejeitadas ( outras podem ser rejeitadas agora).

```{r}
train<-subset(train, select=-fare)
m2<-glm(formula = survived ~ ., data = train, family="binomial")
summary(m2)
```

Novamente, vemos que as variáveis embarkedQ e parch foram rejeitadas. Considerando que parch já está sendo explicada pelas variáveis sibsp e sozinho, podemos excluí-la do modelo. Quanto à embarkedQ, vimos na parte inferencial que não rejeitamos a hipótese de que a proporção de sobreviventes dos que embarcaram no porto Q não era diferente da dos que embarcaram no porto S. Então, usaremos essa igualdade na obtenção do modelo final.

```{r}
df["embarked_agg"]<-df$embarked
df$embarked_agg[df$embarked_agg=="Q"]<-"S"
df$embarked_agg<-factor(df$embarked_agg)
train<-df[sample,]
val<-df[-sample,]
train<-subset(train, select=-c(age,fare,parch,embarked))
mf<-glm(formula = survived ~ ., data = train, family="binomial")
summary(mf)
```

Como nenhuma variável foi rejeitada (todos os betas são significamente diferentes de zero), veremos agora se os coeficientes estão coerentes com o que seria esperado. Podemos ver, por exemplo, que a medida que piora a classe de embarque, diminui a probabilidade de sobrevivência (coeficientes estão negativos e "punem" cada vez mais). Contudo, há um pequeno conflito na variável **sibsp**, pois com 1 ou 2 irmãos, a proporção de sobreviventes é maior que a de 0, mas o sinal do coeficiente é negativo. Isto acontece porque com 3 ou mais irmãos vai diminuindo a proporção de sobreviventes e quanto ao 0, ele já é punido pela variável **sozinho**. Até dá para refinar essas variáveis utilizando o agrupamento sugerido na análise descritiva, mas não teríamos melhoria prática.

Então, apliquemos este modelo na base de validação para obter a matriz de confusão e, consequentemente, a acurácia do modelo.

```{r}
res<-predict(mf,val,type="response")
confmatrix<-table(verd=val$survived,pred=res>0.5)
acc<-(confmatrix[1,1]+confmatrix[2,2])/sum(confmatrix)
print(acc)
```

Percebe-se que dos 236 (199+37) passageiros que não sobreviveram, acertamos 199 e dos 157 (108+49) que sobreviveram, acertamos 108. Logo, acertamos 307 dos 393 passageiros existentes na base de validação, o que dá uma **acurácia** de **78,12%**.

    3.Árvore de Decisão Simples
    4.KNN 

A ideia do KNN é classificar um novo elemento observando os k elementos mais próximos, sendo k um valor que chamamos de hiperparâmetro do modelo. Não existe uma fórmula para se obter k, geralmente usa números ímpares para evitar empates (por exemplo, se k fosse 4 e perto do elementos que queremos prever temos 2 passageiros que sobreviveram e 2 que não sobreviveram, qual seria a predição para esse elemento?). Obteremos esse valor treinando o algoritmo iterativamente e verificando qual apresentou a maior acurácia. 

Outro problema que o knn enfrenta é que a variável resposta precisa ser equilibrada, do contrário, fica difícil para a categoria com pouca representatividade "vencer na votação". No caso em tela, temos que a proporção de sobreviventes é de 38,20%, temos, então, um leve desbalanceamento.

Precisamos que todas as variáveis explicativas sejam numéricas. Então, precisaremos fazer alguns outros pré-processamentos (além dos realizados na seção 1).

```{r}
target<-subset(df, select=survived)
df<-subset(df, select=-c(survived,embarked_agg))
df$pclass<-as.integer(df$pclass)#Não quero criar dummies nesta variável porque a ordem importa: classe1>classe2>classe3
library(caret)
dummy<-dummyVars(" ~. ", data=df)
df<-data.frame(predict(dummy,newdata=df))
```

Também precisamos que as variáveis estejam normalizadas (todas as variáveis terão escalas de zero a um, ou seja, não é padronização!) para que todas as distâncias tenham o mesmo peso. Certamente tem alguma função para fazer isso, mas simplesmente podemos construir uma linha:

```{r}
normalize<-function(x) return((x-min(x))/(max(x)-min(x)))
#Aplicando a normalização na base:
df_norm<-as.data.frame(lapply(df, normalize))
```

Podemos, agora, aplicar o algoritmo KNN.
```{r}

```




## Conclusões.